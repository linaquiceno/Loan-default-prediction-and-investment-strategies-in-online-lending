---
title: "Lending Club Assignment 2"
output:
  pdf_document: default
  html_notebook: default
---

## GLM, RF, GBM Models for Loan Investments

## Lina Quiceno Bejarano, Joshua Pollack, Lauren Sansone

```{r include=FALSE}

#knitting configuration min 10 lines
library(knitr)
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options))  
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines)==1) {        
    if (length(x) > lines) {
      
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
```

All Necessary Libraries

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(lubridate)
library(rpart)
library(rpart.plot)
library(caret)
library(C50)
library('ROCR')
library(ranger)
library(glmnet)
library(xgboost)
library(tidyr)
library(ROSE)
library(broom)
library(rsample)
```

\#Importing the data set

```{r message=FALSE, warning=FALSE}
lcDataSample5m <- read_csv("lcDataSample5m.csv")
lcdf_AR <- lcDataSample5m
```

\#Variable Modifications

```{r, output.lenght=32}
#Remove loans with a status other than charged off and Fully Paid
lcdf_AR <- lcdf_AR %>% filter(loan_status == "Fully Paid" | loan_status == "Charged Off")

#regrouping purpose
lcdf_AR$purpose <- fct_recode(lcdf_AR$purpose, other="wedding", other="renewable_energy")

#Filtering home ownership
lcdf_AR <- lcdf_AR %>% filter(home_ownership == "MORTGAGE" 
                        | home_ownership == "OWN" 
                        | home_ownership == "RENT")

lcdf_AR <- lcdf_AR %>% mutate_if(is.character, as.factor)

lcdf_AR <- lcdf_AR %>% mutate(loan_status=as.factor(loan_status)) #this is a redundancy

##Building annRet 
lcdf_AR$annRet <- ((lcdf_AR$total_pymnt -lcdf_AR$funded_amnt)/lcdf_AR$funded_amnt)*(12/36)*100
```

## Calculating actual loan returns

```{r message=FALSE, warning=FALSE}

#  First step is to past "01-" to the character string, to get something like "01-Dec-2018", i.e. first of each month 
lcdf_AR$last_pymnt_d<-paste(lcdf_AR$last_pymnt_d, "-01", sep = "")
#     Then convert this character to a date type variable
lcdf_AR$last_pymnt_d<-parse_date_time(lcdf_AR$last_pymnt_d,  "myd")

#Determining Acutal Term or setting term to 3 years
lcdf_AR$actualTerm <- ifelse(lcdf_AR$loan_status=="Fully Paid", as.duration(lcdf_AR$issue_d  %--% lcdf_AR$last_pymnt_d)/dyears(1), 3)

#Then, considering this actual term, the actual annual return is
lcdf_AR$actualReturn <- ifelse(lcdf_AR$actualTerm>0, ((lcdf_AR$total_pymnt -lcdf_AR$funded_amnt)/lcdf_AR$funded_amnt)*(1/lcdf_AR$actualTerm)*100, 0)

```

\#Removing Variables due to leakage

```{r, output.lenght=32}
## Removing variables for data leakage
lcdf_AR <- lcdf_AR %>% select(-c(acc_now_delinq, collection_recovery_fee, debt_settlement_flag, debt_settlement_flag_date, deferral_term, delinq_2yrs, disbursement_method, hardship_amount, hardship_dpd, hardship_end_date, hardship_flag, hardship_last_payment_amount,hardship_length, hardship_loan_status, hardship_payoff_balance_amount, hardship_reason, hardship_status, hardship_start_date, hardship_type, inq_last_6mths, issue_d, last_credit_pull_d, last_pymnt_amnt, last_pymnt_d, mths_since_last_delinq, mths_since_last_major_derog, next_pymnt_d, open_acc, orig_projected_additional_accrued_interest, out_prncp, out_prncp_inv, payment_plan_start_date, pub_rec, pymnt_plan, recoveries, revol_bal, revol_util, settlement_date, settlement_amount, settlement_status, settlement_percentage, settlement_term, tot_coll_amt, tot_cur_bal, total_acc, total_pymnt, total_pymnt_inv, total_rec_int, total_rec_late_fee, total_rec_prncp))
                           
```

\#Removing variables for other reasons

```{r, output.lenght=32}
## Removing variables for other reasons
lcdf_AR <- lcdf_AR %>% select(-c(addr_state, all_util, annual_inc_joint, application_type, desc, dti_joint, emp_title, funded_amnt, funded_amnt_inv, il_util, inq_fi, inq_last_12m, max_bal_bc, mths_since_last_record, mths_since_rcnt_il, mths_since_recent_bc_dlq, mths_since_recent_revol_delinq, open_acc_6m, open_act_il, open_il_12m, open_il_24m,  open_rv_12m, open_rv_24m, policy_code, revol_bal_joint, sec_app_chargeoff_within_12_mths, sec_app_collections_12_mths_ex_med, sec_app_earliest_cr_line, sec_app_inq_last_6mths, sec_app_mort_acc, sec_app_mths_since_last_major_derog, sec_app_num_rev_accts, sec_app_open_acc, sec_app_open_act_il, sec_app_revol_util, term, title, total_bal_il, total_cu_tl, url, verification_status_joint, zip_code, X1))
```

\#Replacing Some Missing Values

```{r, output.lenght=32}
lcdf_AR<- lcdf_AR %>% replace_na(list(mths_since_last_delinq=500, bc_open_to_buy=median(lcdf_AR$bc_open_to_buy, na.rm=TRUE), mo_sin_old_il_acct=1000, mths_since_recent_bc=1000, mths_since_recent_inq=50, num_tl_120dpd_2m = median(lcdf_AR$num_tl_120dpd_2m, na.rm=TRUE), percent_bc_gt_75 = median(lcdf_AR$percent_bc_gt_75, na.rm=TRUE), bc_util=median(lcdf_AR$bc_util, na.rm=TRUE) ))
```

\#Removing Variables with \>60% missing values

```{r}
    #remove variables which have more than 60% missing values
nm<-names(lcdf_AR)[colMeans(is.na(lcdf_AR))>0.6]
lcdf_AR <- lcdf_AR %>% select(-nm)

```

\#Removing Variables with lots of zeros

```{r, output.lenght=32}
lcdf_AR <- lcdf_AR %>% select(-c(collections_12_mths_ex_med, chargeoff_within_12_mths, delinq_amnt, num_tl_120dpd_2m, num_tl_30dpd, num_tl_90g_dpd_24m, mort_acc, pub_rec_bankruptcies, tax_liens))
```

\#Spliting Data into Training, Validation, and Test Sets

```{r}
set.seed(123)

fractionTraining   <- 0.70
fractionValidation <- 0.00
fractionTest       <- 0.30

# Compute sample sizes.
sampleSizeTraining   <- floor(fractionTraining   * nrow(lcdf_AR))
sampleSizeValidation <- floor(fractionValidation * nrow(lcdf_AR))
sampleSizeTest       <- floor(fractionTest       * nrow(lcdf_AR))

# Create the randomly-sampled indices for the dataframe. Use setdiff() to
# avoid overlapping subsets of indices.
indicesTraining    <- sort(sample(seq_len(nrow(lcdf_AR)), size=sampleSizeTraining))
indicesNotTraining <- setdiff(seq_len(nrow(lcdf_AR)), indicesTraining)
indicesValidation  <- sort(sample(indicesNotTraining, size=sampleSizeValidation))
indicesTest        <- setdiff(indicesNotTraining, indicesValidation)

# Finally, output the three dataframes for training, validation and test.
lcdfTrn_AR <- lcdf_AR[indicesTraining, ]
lcdfVal_AR <- lcdf_AR[indicesValidation, ]
lcdfTst_AR <- lcdf_AR[indicesTest, ]

```

## Question 1

\#Linear model turning into factor

```{r, output.lenght=32}
#Make sure that "fully paid" is 1 in the factor variable
levels(lcdfTrn_AR$loan_status)
yTrn<-factor(if_else(lcdfTrn_AR$loan_status=="Fully Paid", '1', '0') )
xDTrn<-lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)
#the Test set
glmls_cv<- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial")
```

\#Removing variables and running cv

```{r}
#remove variables that would not be x variables
xDTrn<-lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)
#running cross validation 
glmls_cv<- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial")

#plotting the model
plot(glmls_cv)
```

\#Ridge and Lasso

```{r, output.lenght=32}
#experimenting with Ridge 
glmls_Ridge<- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", alpha=0)
plot(glmls_Ridge)

#experimenting between Ridge and Lasso
glmls_Mid<- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", alpha=.5)
plot(glmls_Mid)

#finding the minimum lambda
glmls_cv$lambda.min
#finding within 1 standard error
glmls_cv$lambda.1se

```

\#Getting lambda values

```{r, output.lines=50}
#values for all coefficients
coef(glmls_cv, s = glmls_cv$lambda.min)
#showing coefficients using tidy getting rid of all zeros
tidy(coef(glmls_cv, s = glmls_cv$lambda.1se))

#values corresponding to graph
glmls_cv$glmnet.fit

```

```{r, output.lenght=32}
#finding lambda that creates the optimal deviance
which(glmls_cv$lambda == glmls_cv$lambda.1se)

#finding the lambda that has the best auc level
glmls_cv_auc<- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure = "auc")
plot(glmls_cv_auc)
```

\#Making Predictions

```{r, output.lenght=32}
#making predictions for Lambda min with Training and Test
glmPredls_Min=predict ( glmls_cv,data.matrix(xDTrn), s="lambda.min" ) 
head(glmPredls_Min)

#making predictions with probability for Lambda min Training 
glmPredls_pMin=predict(glmls_cv,data.matrix(xDTrn), s="lambda.min", type="response" )
head(glmPredls_pMin) 

#making predictions for Lambda.se
glmPredls_SE=predict ( glmls_cv,data.matrix(xDTrn), s="lambda.1se" ) 
head(glmPredls_SE)

#making predictions with probability for Lambda.1se
glmPredls_pSE=predict(glmls_cv,data.matrix(xDTrn), s="lambda.1se", type="response" )
head(glmPredls_pSE) 

```

\#auc values

```{r, output.lenght=32}
predsauc <- prediction(glmPredls_pMin, lcdfTrn_AR$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerf <- performance(predsauc, "auc")


#auc value for lambda.se
predsaucSE <- prediction(glmPredls_pSE, lcdfTrn_AR$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerfSE <- performance(predsaucSE, "auc")
```

\#balancing data

```{r, output.lenght=32}
#to consider a more balanced data, we can include example weights
wts=if_else(yTrn==0, 1-sum(yTrn==0)/length(yTrn), 1-sum(yTrn==1)/length(yTrn) )
glmsw_cv<- cv.glmnet(data.matrix(xDTrn), yTrn, family = "binomial", weights= wts )
plot(glmsw_cv)

predsauc <- prediction(glmPredls_pMin, lcdfTrn_AR$loan_status, label.ordering =
                         c("Charged Off", "Fully Paid"))
aucPerf <- performance(predsauc, "auc")
#need auc@y.values. need to get that package
```

\#standard error

```{r, output.lenght=32}
#model for standard error
glmls_1 <- glmnet(data.matrix(xDTrn), yTrn, family="binomial", lambda = glmls_cv$lambda.1se )
glmls_1

tidy(glmls_1)

#
glmls_1b <- glmnet(data.matrix(xDTrn), yTrn, family="binomial",lambda = glmls_cv$lambda)
tidy(coef(glmls_1b, s= glmls_cv$lambda.1se))
```

\#without regularization

```{r message=FALSE, warning=FALSE}
#linear model without regularization
#get the variables with non-zero coefficients from the regularized model
nzCoef<-tidy(coef(glmls_cv, s= glmls_cv$lambda.1se))
nzCoefVars <- nzCoef[-1,1] 

#the model without regularization
glmls_nzv_2 <- glm(yTrn ~ data.matrix(xDTrn %>% select(nzCoefVars)), family=binomial())

summary(glmls_nzv_2)
glm(formula = yTrn ~ data.matrix(xDTrn %>% select(nzCoefVars)),
    family = binomial())
```

## Question 2

\#Building a Random Forest Model to Predict Actual Returns

```{r, output.lenght=32}
rf_AR <- ranger(actualReturn ~., data=subset(lcdfTrn_AR, select=-c(annRet, actualTerm, loan_status)), num.trees = 200, importance = 'permutation')
```

\#RF -- Training data

```{r}
rfPredRet_trn_AR<- predict(rf_AR,  lcdfTrn_AR)
sqrt(mean((rfPredRet_trn_AR$predictions- lcdfTrn_AR$actualReturn)^2))

plot ((predict(rf_AR,  lcdfTrn_AR))$predictions, lcdfTrn_AR$actualReturn)
```

\#RF -- Performance by Deciles for Training Data

```{r, output.lenght=32}
predRet_Trn_AR<- lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_ARtrn=(predict(rf_AR, lcdfTrn_AR))$predictions)

predRet_Trn_AR<- predRet_Trn_AR %>% mutate(tile=ntile(-predRet_ARtrn, 10))

predRet_Trn_AR %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_ARtrn),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),   totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"))
```

\#RF -- Test data

```{r, output.lenght=32}
rfPredRet_Tst_AR<- predict(rf_AR,  lcdfTst_AR)
sqrt(mean((rfPredRet_Tst_AR$predictions- lcdfTst_AR$actualReturn)^2))

plot ((predict(rf_AR,  lcdfTst_AR))$predictions, lcdfTst_AR$actualReturn)
```

\#RF -- Performance by Deciles for Test Data

```{r, output.lenght=32}
predRet_Tst_AR<- lcdfTst_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_ARtst=(predict(rf_AR, lcdfTst_AR))$predictions)

predRet_Tst_AR<- predRet_Tst_AR %>% mutate(tile=ntile(-predRet_ARtst, 10))

predRet_Tst_AR %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_ARtst),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),   totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"))
```

\#Balancing the Training Data with over and under sampling or combination of both

```{r, output.lenght=32}
lcdfSplit_AR <- initial_split(lcdf_AR, prop=0.7)
lcdfTrn_Bal <- training(lcdfSplit_AR)
lcdfTst_Bal <- testing(lcdfSplit_AR)

us_lcdfTrn_AR<-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn_Bal), na.action= na.pass, method="under", p=0.5)$data

os_lcdfTrn_AR<-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn_Bal), na.action= na.pass, method="over", p=0.5)$data

bs_lcdfTrn_AR<-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn_Bal), na.action= na.pass, method="both", p=0.5)$data

bs_lcdfTrn_AR%>% group_by(loan_status) %>% count()
```

\#\#Building A RF w/ balanced data \#Building RF Under Sampling

```{r, output.lenght=32}
rf_AR_us <- ranger(actualReturn ~., data=subset(us_lcdfTrn_AR, select=-c(annRet, actualTerm, loan_status)), num.trees = 200, importance='permutation')
```

\#RF Under Sampling Results

```{r, output.lenght=32}
rfPredRet_trn_us<- predict(rf_AR_us,  us_lcdfTrn_AR)
sqrt(mean((rfPredRet_trn_us$predictions- us_lcdfTrn_AR$actualReturn)^2))

plot ((predict(rf_AR_us,  us_lcdfTrn_AR))$predictions, us_lcdfTrn_AR$actualReturn)

predRet_Trn_us<- us_lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_ARtrn_us=(predict(rf_AR_us, us_lcdfTrn_AR))$predictions)

predRet_Trn_us<- predRet_Trn_us %>% mutate(tile=ntile(-predRet_ARtrn_us, 10))

predRet_Trn_us %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_ARtrn_us),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),   totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"))
```

\#RF Over Sampling

```{r}
rf_AR_os <- ranger(actualReturn ~., data=subset(os_lcdfTrn_AR, select=-c(annRet, actualTerm, loan_status)), num.trees = 200, importance='permutation')
```

\#RF Train Results for Over Sampling

```{r, output.lenght=32}
rfPredRet_trn_os<- predict(rf_AR_os,  os_lcdfTrn_AR)
sqrt(mean((rfPredRet_trn_os$predictions- os_lcdfTrn_AR$actualReturn)^2))

plot ((predict(rf_AR_os,  os_lcdfTrn_AR))$predictions, os_lcdfTrn_AR$actualReturn)

predRet_Trn_os<- os_lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_ARtrn_os=(predict(rf_AR_os, os_lcdfTrn_AR))$predictions)

predRet_Trn_os<- predRet_Trn_os %>% mutate(tile=ntile(-predRet_ARtrn_os, 10))

predRet_Trn_os %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_ARtrn_os),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),   totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"))
```

\#RF Over Sampling Test Results

```{r, output.lenght=32}
rfPredRet_Tst_os<- predict(rf_AR_os,  lcdfTst_AR)
sqrt(mean((rfPredRet_Tst_os$predictions- lcdfTst_AR$actualReturn)^2))

plot ((predict(rf_AR_os,  lcdfTst_AR))$predictions, lcdfTst_AR$actualReturn)

predRet_Tst_os<- lcdfTst_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_ARTst_os=(predict(rf_AR_os, lcdfTst_AR))$predictions)

predRet_Tst_os<- predRet_Tst_os %>% mutate(tile=ntile(-predRet_ARTst_os, 10))

predRet_Tst_os %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_ARTst_os),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),   totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"))
```

\#Both \#Building RF for Both (combination of over and under sampling)

```{r, output.lenght=32}
rf_AR_bs <- ranger(actualReturn ~., data=subset(bs_lcdfTrn_AR, select=-c(annRet, actualTerm, loan_status)), num.trees = 200, importance='permutation')
```

\#RF Both Train results

```{r, output.lenght=32}
rfPredRet_Trn_bs<- predict(rf_AR_bs,  bs_lcdfTrn_AR)
sqrt(mean((rfPredRet_Trn_bs$predictions- bs_lcdfTrn_AR$actualReturn)^2))

plot ((predict(rf_AR_bs,  bs_lcdfTrn_AR))$predictions, bs_lcdfTrn_AR$actualReturn)

predRet_Trn_bs<- bs_lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_ARTrn_bs=(predict(rf_AR_bs, bs_lcdfTrn_AR))$predictions)

predRet_Trn_bs<- predRet_Trn_bs %>% mutate(tile=ntile(-predRet_ARTrn_bs, 10))

predRet_Trn_bs %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_ARTrn_bs),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),   totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"))
```

\#RF Both Test results

```{r, output.lenght=32}
rfPredRet_Tst_bs<- predict(rf_AR_bs,  lcdfTst_AR)
sqrt(mean((rfPredRet_Tst_bs$predictions- lcdfTst_AR$actualReturn)^2))

plot ((predict(rf_AR_bs,  lcdfTst_AR))$predictions, lcdfTst_AR$actualReturn)

predRet_Tst_bs<- lcdfTst_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_ARTst_bs=(predict(rf_AR_bs, lcdfTst_AR))$predictions)

predRet_Tst_bs<- predRet_Tst_bs %>% mutate(tile=ntile(-predRet_ARTst_bs, 10))

predRet_Tst_bs %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_ARTst_bs),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),   totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"))
```

\#Building glm Model

```{r, output.lenght=32}
#creating data set for glm model
df4_glm <-lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)

glmRet_cv <- cv.glmnet(data.matrix(df4_glm), lcdfTrn_AR$actualReturn, family="gaussian")

plot(glmRet_cv)

```

\#Some Metrics for glm model

```{r}
glmRet_cv$lambda.min

glmRet_cv$lambda.1se


coef(glmRet_cv, s="lambda.1se") %>% tidy()

coef(glmRet_cv, s="lambda.min")

```

\#Predictions for glm Model for Training Data

```{r, output.lenght=32}
#Performance of glm model for lambda min
predRet_Trn_AR_glm <- lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_glm=  predict(glmRet_cv, data.matrix(lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" )) 

####May want to run predictions with lambda.1se and compare

#spliting into deciles
predRet_Trn_AR_glm<- predRet_Trn_AR_glm%>% mutate(tile=ntile(-predRet_glm, 10))

predRet_Trn_AR_glm %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_glm),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

\#Predictions of glm Model for Test Data

```{r, output.lenght=32}
#Performance of glm model for lambda.min
predRet_Tst_AR_glm <- lcdfTst_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_glm=  predict(glmRet_cv, data.matrix(lcdfTst_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" ) ) 

####May want to run predictions with lambda.1se and compare

#spliting into deciles
predRet_Tst_AR_glm<- predRet_Tst_AR_glm%>% mutate(tile=ntile(-predRet_glm, 10))

predRet_Tst_AR_glm %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_glm),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

\#alpha=0 (Ridge Regression) for glm model

```{r}
glmRet_cv_a0<- cv.glmnet(data.matrix(df4_glm),   lcdfTrn_AR$actualReturn, family="gaussian", alpha=0)

plot(glmRet_cv_a0)

#1se
glmRet_cv_a0$lambda.1se
#min
glmRet_cv_a0$lambda.min

coef(glmRet_cv_a0, s="lambda.1se")

coef(glmRet_cv_a0, s="lambda.min")
```

\#Predictions for alpha=0 Model for Training Data

```{r, output.lenght=32}
#Performance of glm model for lambda min
predRet_Trn_AR_a0 <- lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_a0=  predict(glmRet_cv, data.matrix(lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" )) 

####May want to run predictions with lambda.1se and compare


#spliting into deciles
predRet_Trn_AR_a0<- predRet_Trn_AR_a0 %>% mutate(tile=ntile(-predRet_a0, 10))

predRet_Trn_AR_a0 %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_a0),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

\#alpha = x for glm model

```{r}
glmRet_cv_a2<- cv.glmnet(data.matrix(df4_glm),   lcdfTrn_AR$actualReturn, family="gaussian",    alpha=0.2)

plot(glmRet_cv_a2)

#1se
glmRet_cv_a2$lambda.1se
#min
glmRet_cv_a2$lambda.min


coef(glmRet_cv_a2, s="lambda.1se")

coef(glmRet_cv_a2, s="lambda.min")
```

\#Predictions for alpha=2 Model for Training Data

```{r, output.lenght=32}
#Performance of glm model for lambda min
predRet_Trn_AR_a2 <- lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_a2=  predict(glmRet_cv, data.matrix(lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" )) 

####May want to run predictions with lambda.1se and compare

#spliting into deciles
predRet_Trn_AR_a2<- predRet_Trn_AR_a2 %>% mutate(tile=ntile(-predRet_a2, 10))

predRet_Trn_AR_a2 %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_a2),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

\#\#Building glm model with balanced data

\#Building glm Model with under sampled data

```{r, output.lenght=32}
#creating data set for glm model
df4_glm_us <-us_lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)

glmRet_cv_us <- cv.glmnet(data.matrix(df4_glm_us), us_lcdfTrn_AR$actualReturn, family="gaussian")

plot(glmRet_cv_us)

```

\#Some Metrics for glm under sampling

```{r}
glmRet_cv_us$lambda.min

glmRet_cv_us$lambda.1se

coef(glmRet_cv_us, s="lambda.1se") %>% tidy()

coef(glmRet_cv_us, s="lambda.min")

```

\#Predictions for glm under sampling

```{r, output.lenght=32}
#Performance of glm model for lambda min
predRet_Trn_us_glm <- us_lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_glm_us=  predict(glmRet_cv_us, data.matrix(us_lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" ))

#spliting into deciles
predRet_Trn_us_glm<- predRet_Trn_us_glm%>% mutate(tile=ntile(-predRet_glm_us, 10))

predRet_Trn_us_glm %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_glm_us),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

\#Building glm Model with over sampled data

```{r, output.lenght=32}
#creating data set for glm model
df4_glm_os <-os_lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)

glmRet_cv_os <- cv.glmnet(data.matrix(df4_glm_os), os_lcdfTrn_AR$actualReturn, family="gaussian")

plot(glmRet_cv_os)

```

\#Some Metrics for glm over sampling

```{r}
glmRet_cv_os$lambda.min

glmRet_cv_os$lambda.1se

coef(glmRet_cv_os, s="lambda.1se") %>% tidy()

coef(glmRet_cv_os, s="lambda.min")

```

\#Predictions for glm over sampling

```{r, output.lenght=32}
#Performance of glm model for lambda min
predRet_Trn_os_glm <- os_lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_glm_os=  predict(glmRet_cv_os, data.matrix(os_lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" ))

#spliting into deciles
predRet_Trn_os_glm<- predRet_Trn_os_glm%>% mutate(tile=ntile(-predRet_glm_os, 10))

predRet_Trn_os_glm %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_glm_os),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

\#Building glm Model with both sampled data

```{r, output.lenght=32}
#creating data set for glm model
df4_glm_bs <-bs_lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)

glmRet_cv_bs <- cv.glmnet(data.matrix(df4_glm_bs), bs_lcdfTrn_AR$actualReturn, family="gaussian")

plot(glmRet_cv_bs)

```

\#Some Metrics for glm both sampling

```{r, output.lenght=32}
glmRet_cv_bs$lambda.min

glmRet_cv_bs$lambda.1se

coef(glmRet_cv_bs, s="lambda.1se") %>% tidy()

coef(glmRet_cv_bs, s="lambda.min")

```

\#Predictions for glm both sampling

```{r, output.lenght=32}
#Performance of glm model for lambda min
predRet_Trn_bs_glm <- bs_lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_glm_bs=  predict(glmRet_cv_bs, data.matrix(bs_lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" ))

#spliting into deciles
predRet_Trn_bs_glm<- predRet_Trn_bs_glm%>% mutate(tile=ntile(-predRet_glm_bs, 10))

predRet_Trn_bs_glm %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_glm_bs),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

### XGBOOST Building the model

```{r, output.lenght=32}
# we are predicting actualReturn a numeric variable

#converting factor variables to dummy-variables
lcdf_ARdum2<-dummyVars(~.,data=lcdf_AR %>% select(-actualReturn))

dxlcdf2 <- predict(lcdf_ARdum2, lcdf_AR)

#Training, test subsets
dxlcdfTrn2 <- dxlcdf2[indicesTraining,] 
colcdfTrn2 <- lcdf_AR$actualReturn[indicesTraining]
dxlcdfTst2 <- dxlcdf2[-indicesTraining,]
colcdfTst2 <- lcdf_AR$actualReturn[indicesTest]

#Creating Training and Test xgb matrices need it to run the model
dxTrn2 <- xgb.DMatrix(subset(dxlcdfTrn2, select=-c(annRet, actualTerm)), label=colcdfTrn2)
dxTst2 <- xgb.DMatrix(subset( dxlcdfTst2,select=-c(annRet, actualTerm)), label=colcdfTst2)
# (annRet, actualTerm) These variables are useful for performance assessment, but should not be used in the model

xgbWatchlist2 <- list(train = dxTrn2, eval = dxTst2)
#we can watch the progress of learning thru performance on these datasets
# Including a xgbWatchlist so the early_stopping_rounds = 10 that we are going to use in the model can use it as a base to know when to stop
```

\#XGBOOST Show how you systematically experiment with different parameters to find the best models. Compare model performance. Finding which hyper-parameters work best -- experiment with a grid of parameter values

```{r, output.lines=50, output.lenght=32}

#Weight Calculations
#sqrt(sum(dxlcdfTrn==0) / sum(dxlcdfTrn==1))   #7.950299

#Parameter with the grid of options we want to test to find the best for the model
xgbParamGrid2 <- expand.grid(
max_depth = c(2, 5),
eta = c(0.001, 0.01, 0.1) )

#Parameter list
xgbParam2 <- list (
booster = "gbtree",
objective = "reg:squarederror",
#scale_pos_weight = 7.950299,
min_child_weight=1,
colsample_bytree=0.6
)

for(i in 1:nrow(xgbParamGrid2)) {
xgb_tune<- xgb.train(data=dxTrn2,xgbParam2,
nrounds=1000, early_stopping_rounds = 10, xgbWatchlist2,
eta=xgbParamGrid2$eta[i], max_depth=xgbParamGrid2$max_depth[i] )
xgbParamGrid2$bestTree[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$iter
xgbParamGrid2$bestPerf[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$eval_rmse
}

```

\#Plugin the tune parameters

```{r, output.lenght=32}
xgbParamGrid2 

# max_depth eta bestTree bestPerf
# 2	0.001	1000	5.534117	
# 5	0.001	1000	5.395167	
# 2	0.010	1000	4.006708	
# 5	0.010	536	3.990832	
# 2	0.100	154	4.004697	
# 5	0.100	66	3.996803	<- almost the lower error this is better than 3.990832 because it use less iteratoin
 
xgbParam3 <- list(
max_depth = 5,
eta = 0.100,
booster = "gbtree",
objective = "reg:squarederror",
#scale_pos_weight = 7.950299,
min_child_weight=1,
colsample_bytree=0.6
)

# XGBOOST running the model with the best parameters found with the for loop 
xgb_lsM2 <- xgb.train(xgbParam3, dxTrn2, nrounds = xgb_tune$best_iteration)
```

\#XGBOOST evaluation of the model

```{r, output.lenght=32}
#Using the predicting function to get the scores in the training data  set
xpredTrn2<-predict(xgb_lsM2, dxTrn2)
head(xpredTrn2)

#Using the predicting function to get the scores in the test data set
xpredTst2<-predict(xgb_lsM2, dxTst2)

#Error
sqrt(mean((xpredTst2- colcdfTst2)^2))

#Performance by deciles
scoreTst_xgb_ls2 <- lcdfTst_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score=xpredTst2)

scoreTst_xgb_ls2 <- scoreTst_xgb_ls2 %>% mutate(tile=ntile(-score, 10))
scoreTst_xgb_ls2 %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )


```

########## 

\#3 \#Creating the RF based on Assignment 1 for all Grade loans

```{r, output.lenght=32}
#myweights = ifelse(lcdfTrn_AR$loan_status == "Charged Off", 5, 1)

RF_Asst1 <- ranger(loan_status ~., data=subset(lcdfTrn_AR, select=-c(annRet, actualTerm, actualReturn)), num.trees =200, min.node.size=1, importance='impurity', probability=TRUE)
#case.weights= myweights)
```

\#Performance of RF for all grades in Deciles M1

```{r, output.lenght=32}
ag_scoreTstRF <- lcdfTst_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
mutate(score=(predict(RF_Asst1,lcdfTst_AR))$predictions[,"Fully Paid"])

ag_scoreTstRF <- ag_scoreTstRF %>% mutate(tile=ntile(-score, 10))

ag_scoreTstRF %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

\#Rf Returns selected by grade M2 - all grades

```{r, output.lenght=32}
#Choose the Actual Returns Random forest we want for here
rfPredRet_Tst_ag<- predict(rf_AR_os,  lcdfTst_AR)
sqrt(mean((rfPredRet_Tst_ag$predictions- lcdfTst_AR$actualReturn)^2))

plot ((predict(rf_AR_os,  lcdfTst_AR))$predictions, lcdfTst_AR$actualReturn)
```

\#Rf -- Performance by Deciles for Test Data - all grades

```{r, output.lenght=32}
ag_predRet_Tst<- lcdfTst_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_agTst=(predict(rf_AR_os, lcdfTst_AR))$predictions)

ag_predRet_Tst<- ag_predRet_Tst %>% mutate(tile=ntile(-predRet_agTst, 10))

ag_predRet_Tst %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_agTst),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),   totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"))
```

\#Consider Top d deciles from Model 2(actualReturn), ranked by M1 scores(loan_Status) all grades

```{r, output.lenght=32}
d=1
pRetSc_RF_ag <- ag_predRet_Tst %>% mutate(poScore=ag_scoreTstRF$score)
pRet_d_RF_ag <- pRetSc_RF_ag %>% filter(tile<=d)
pRet_d_RF_ag<- pRet_d_RF_ag %>% mutate(tile2=ntile(-poScore, 20))

pRet_d_RF_ag %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(predRet_agTst),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

\#\#Boosting

\#Creating the Boosting Model based on Assignment 1 for all Grade loans

```{r, output.lines=70, output.lenght=32}
# use the dummyVars function in the 'caret' package to convert factor variables to dummy-variables, do not include loan_status for this 
fdum1<-dummyVars(~.,data=lcdf_AR %>% select(-loan_status)) 

dxlcdf1 <- predict(fdum1, lcdf_AR)
# for loan_status, check levels and convert to dummy vars and keep the class label of interest 
levels(lcdf_AR$loan_status)

#"Charged Off" "Fully Paid"  
#converting to dummy variables
dylcdf1 <- class2ind(lcdf_AR$loan_status, drop2nd = FALSE)
# we decided we want to keep "Fully Paid"
colcdf1 <- dylcdf1 [ ,2]

#Training, test subsets 
dxlcdfTrn1 <- dxlcdf1[indicesTraining,] 
colcdfTrn1 <- colcdf1[indicesTraining] 
dxlcdfTst1 <- dxlcdf1[indicesTest,] 
colcdfTst1 <- colcdf1[indicesTest]

#Creating of xgb.DMatrix
dxTrn1 <- xgb.DMatrix(subset(dxlcdfTrn1, select=-c(annRet, actualTerm, actualReturn)), label=colcdfTrn1) 
dxTst1 <- xgb.DMatrix(subset(dxlcdfTst1, select=-c(annRet, actualTerm, actualReturn)), label=colcdfTst1)

#we can watch the progress of learning thru performance on these datasets
xgbWatchlist1 <- list(train = dxTrn1, eval = dxTst1)

#defining weights
sqrt(sum(dxlcdfTrn1==0) / sum(dxlcdfTrn1==1))  #8.536599

#use cross-validation on training dataset to determine best model
xgbParamGrid1 <- expand.grid( max_depth = c(2, 5), eta = c(0.001, 0.01, 0.1) )
xgbParam1 <- list (booster = "gbtree", objective = "binary:logistic", min_child_weight=1, colsample_bytree=0.6,eval_metric="error", eval_metric = "auc")

for(i in 1:nrow(xgbParamGrid1)) {
xgb_tune1<- xgb.train(data=dxTrn1,xgbParam1,
nrounds=1000, early_stopping_rounds = 10, xgbWatchlist1,
eta=xgbParamGrid1$eta[i], max_depth=xgbParamGrid1$max_depth[i] )
xgbParamGrid1$bestTree[i] <- xgb_tune1$evaluation_log[xgb_tune1$best_iteration]$iter
xgbParamGrid1$bestPerf[i] <- xgb_tune1$evaluation_log[xgb_tune1$best_iteration]$eval_auc
}

```

```{r, output.lenght=32}
xgbParamGrid1

# max_depth eta bestTree bestPerf 
# 2	0.001	7	0.677577	
# 5	0.001	26	0.688194	
# 2	0.010	58	0.682594	
# 5	0.010	66	0.691801	
# 2	0.100	124	0.699748	
# 5	0.100	62	0.699370	

xgbParam_Best1 <- list (booster = "gbtree", objective = "binary:logistic", min_child_weight=1, colsample_bytree=0.6, scale_pos_weight = 8.53, max_depth = 2, eta = 0.001)

# XGBOOST running the model with the best parameters found with the for loop 
xgb_lsM1 <- xgb.train(xgbParam_Best1, dxTrn1, nrounds = xgb_tune1$best_iteration)

#XGBOOST evaluation of the model
#Using the predicting function to get the scores in the training data  set
xpredTrn1<-predict(xgb_lsM1, dxTrn1)
head(xpredTrn1)

#Using the predicting function to get the scores in the test data set
xpredTst1<-predict(xgb_lsM1, dxTst1)
head(xpredTst1)

#Auc
#ROC, AUC performance
#confusion matrix 
table(pred=as.numeric(xpredTst1>0.5), act=colcdfTst1)

#ROC, AUC performance
pred_xgb_lsM1<-prediction(xpredTst1, lcdfTst_AR$loan_status,
label.ordering = c("Charged Off", ("Fully Paid")))
aucPerf_xgb_lsM1<-performance(pred_xgb_lsM1, "tpr", "fpr")
plot(aucPerf_xgb_lsM1)
abline(a=0, b= 1)

#variable importance
xgb.importance(model = xgb_lsM1) %>% view()


```

\#XGBOOST Performance of Boosting A-G in Deciles M1

```{r, output.lenght=32}
xpredTstM1<-predict(xgb_lsM1, dxTst1)

scoreTst_xgb_ls1 <- lcdfTst_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score=xpredTst1)

scoreTst_xgb_ls1 <- scoreTst_xgb_ls1 %>% mutate(tile=ntile(-score, 10))
scoreTst_xgb_ls1 %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totE=sum(grade=="G"), )

```

\#XGBOOST Performance of Boosting A-G in Deciles M2

```{r, output.lenght=32}
xpredTstM2<-predict(xgb_lsM2, dxTst2)

scoreTst_xgb_ls2 <- lcdfTst_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score2=xpredTst2)

scoreTst_xgb_ls2 <- scoreTst_xgb_ls2 %>% mutate(tile=ntile(-score2, 10))
scoreTst_xgb_ls2 %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score2), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totE=sum(grade=="G"), )

```

\#XGBOOST-Consider Top d deciles from Model 2(actualReturn), ranked by M1 scores(loan_Status) all grades

```{r, output.lenght=32}
d=1

pRetSc <- scoreTst_xgb_ls2 %>% mutate(poScore=scoreTst_xgb_ls1$score)
pRet_d <- pRetSc %>% filter(tile<=d)
pRet_d<- pRet_d %>% mutate(tile2=ntile(-poScore, 10))

pRet_d %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(score2),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

\#Performance of glm model for all grade loans in deciles for M1

```{r, output.lenght=32}
predLS_glm <- lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(glmPredls_pMin=predict(glmls_cv,data.matrix(xDTrn), s="lambda.min", type="response" ))


predLS_glm<- predLS_glm%>% mutate(tile=ntile(-glmPredls_pMin, 10))

predLS_glm %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(glmPredls_pMin),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

\#Actual Returns selected by grade M2 all grades

```{r, output.lenght=32}
#Performance of glm model for lambda min
predRet_Trn_glm <- lcdfTrn_AR %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_glm=  predict(glmRet_cv, data.matrix(lcdfTrn_AR %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" ))

predRet_Trn_glm<- predRet_Trn_glm%>% mutate(tile=ntile(-predRet_glm, 10))

predRet_Trn_glm %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_glm),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

\#glm - Consider Top d deciles from Model 2(actualReturn), ranked by M1 scores(loan_Status) all grades

```{r, output.lenght=32}
d=1
pRetSc_glm <- predRet_Trn_glm %>% mutate(poScore=predLS_glm$glmPredls_pMin)
pRet_d_glm <- pRetSc_glm %>% filter(tile<=d)
pRet_d_glm<- pRet_d_glm %>% mutate(tile2=ntile(-poScore, 20))


pRet_d_glm %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(predRet_glm),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

\#4 Modeling Loan Status on lower grade loans

\#Create a RF model for low grade C-G loans M1 Loan Status

```{r, output.lenght=32}
#Selecting only Grades C-G
lg_lcdfTrn<-lcdfTrn_AR %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')
lg_lcdfTst<-lcdfTst_AR %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')

#Creating RF for loans in C - G
rf_M1_lg <- ranger(loan_status ~., data=subset(lg_lcdfTrn, select=-c(annRet, actualTerm, actualReturn)), num.trees =200,
probability=TRUE, importance='permutation')
```

\#Performance of RF C-G in Deciles M1

```{r, output.lenght=32}
lg_scoreTstRF <- lg_lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%
mutate(score=(predict(rf_M1_lg,lg_lcdfTst))$predictions[,"Fully Paid"])

lg_scoreTstRF <- lg_scoreTstRF %>% mutate(tile=ntile(-score, 10))

lg_scoreTstRF %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

\#RF Actual Returns selected by grade M2 low grades

```{r, output.lenght=32}
#Choose the Actual Returns Random forest we want for here
rfPredRet_Tst_lg<- predict(rf_AR_os,  lg_lcdfTst)
sqrt(mean((rfPredRet_Tst_lg$predictions- lg_lcdfTst$actualReturn)^2))

plot ((predict(rf_AR_os,  lg_lcdfTst))$predictions, lg_lcdfTst$actualReturn)
```

\#Rf -- Performance by Deciles for Test Data low grades

```{r, output.lenght=32}
lg_predRet_Tst<- lg_lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet_lgTst=(predict(rf_AR_os, lg_lcdfTst))$predictions)

lg_predRet_Tst<- lg_predRet_Tst %>% mutate(tile=ntile(-predRet_lgTst, 10))

lg_predRet_Tst %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(predRet_lgTst),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),   totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"))
```

\#Consider Top d deciles from Model 2(actualReturn), ranked by M1 scores(loan_Status) low grades

```{r, output.lenght=32}
d=1
pRetSc_RF <- lg_predRet_Tst %>% mutate(poScore=lg_scoreTstRF$score)
pRet_d_RF <- pRetSc_RF %>% filter(tile<=d)
pRet_d_RF<- pRet_d_RF %>% mutate(tile2=ntile(-poScore, 20))

pRet_d_RF %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(predRet_lgTst),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

\#4 GLM Lower Grade Models \#Modeling Loan Status on lower grade loans

\#Creating a GLM model for C-G loans M1

```{r, output.lenght=32}
#Selecting only Grades C-G
lg_lcdfTrn<-lcdfTrn_AR %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')
lg_lcdfTst<-lcdfTst_AR %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')
```

\#Finding Lambda Values

```{r,output.lenght=32}
levels(lg_lcdfTrn$loan_status)
yTrnGr<-factor(if_else(lg_lcdfTrn$loan_status=="Fully Paid", '1', '0') )

xDTrnGR <- lg_lcdfTrn %>%select(-loan_status, -actualTerm, -annRet, -actualReturn,)

glmls_cvGR <-cv.glmnet(data.matrix(xDTrnGR), yTrnGr, family="binomial")
plot(glmls_cvGR)

glmls_cvGR$lambda.min

glmls_cvGR$lambda.1se

coef(glmls_cvGR, s=glmls_cvGR$lambda.min)

coef(glmls_cvGR, s=glmls_cvGR$lambda.1se)
```

```{R, output.lenght=32}
glmls_cvGR_auc<- cv.glmnet(data.matrix(xDTrnGR), yTrnGr, family="binomial", type.measure = "auc")
plot(glmls_cvGR_auc)
#loss Value at Lambda.SE
glmls_cvGR_auc$cvm [ which(glmls_cvGR_auc$lambda == glmls_cvGR_auc$lambda.1se) ]

#loss Value at Lambda.Min
glmls_cvGR_auc$cvm [ which(glmls_cvGR_auc$lambda == glmls_cvGR_auc$lambda.min) ]
```

\#Predictions

```{R, output.lenght=32}
#Log value lambda min
glmPredls_1GR=predict ( glmls_cvGR,data.matrix(xDTrnGR), s="lambda.min" )
head(glmPredls_1GR)
#probability lambda min
glmPredls_1GRP=predict ( glmls_cvGR,data.matrix(xDTrnGR), s="lambda.min", type="response") 
head(glmPredls_1GRP)

#Log value Lambda.SE
glmPredls_1GRSE=predict ( glmls_cvGR,data.matrix(xDTrnGR), s="lambda.1se" )
head(glmPredls_1GRSE)

#probability value Lambda.SE
glmPredls_1GRPMin=predict ( glmls_cvGR,data.matrix(xDTrnGR), s="lambda.1se", type="response") 
head(glmPredls_1GRPMin)
```

\#AUC values

```{R, output.lenght=32}
predsaucGR <- prediction(glmPredls_1GRP, lg_lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerfGR <- performance(predsaucGR, "auc")
#performance is worse with the lower grade loans. auc value of only .614
```

\#Balancing Data

```{r, output.lenght=32}
wtsGR=if_else(yTrnGr==0,1-sum(yTrnGr==0)/length(yTrnGr),1-sum(yTrnGr==1)/length(yTrnGr))

glmlswGR_cv<- cv.glmnet(data.matrix(xDTrnGR), yTrnGr, family="binomial", weights = wtsGR)
plot(glmlswGR_cv)

predsaucGRB <- prediction(glmPredls_1GRP, lg_lcdfTrn$loan_status, label.ordering =
c("Charged Off", "Fully Paid"))
aucPerfGRB <- performance(predsaucGRB, "auc")
```

# 4 XGBOOST Creating a data set for grade C and lower

```{r, output.lenght=32}
lcdf_AR_LowGrades<-lcdf_AR %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')
```

\#4 XGBOOST Spliting Data into Training, Validation, and Test Sets

```{r, output.lenght=32}
set.seed(123)

fractionTraining   <- 0.70
fractionValidation <- 0.00
fractionTest       <- 0.30

# Compute sample sizes.
sampleSizeTraining2   <- floor(fractionTraining   * nrow(lcdf_AR_LowGrades))
sampleSizeValidation2 <- floor(fractionValidation * nrow(lcdf_AR_LowGrades))
sampleSizeTest2       <- floor(fractionTest       * nrow(lcdf_AR_LowGrades))

# Create the randomly-sampled indices for the dataframe. Use setdiff() to
# avoid overlapping subsets of indices.
indicesTraining2    <- sort(sample(seq_len(nrow(lcdf_AR_LowGrades)), size=sampleSizeTraining2))
indicesNotTraining2 <- setdiff(seq_len(nrow(lcdf_AR_LowGrades)), indicesTraining2)
indicesValidation2  <- sort(sample(indicesNotTraining2, size=sampleSizeValidation2))
indicesTest2       <- setdiff(indicesNotTraining2, indicesValidation2)

# Finally, output the three dataframes for training, validation and test.
lcdfTrn_AR2 <- lcdf_AR_LowGrades[indicesTraining2, ]
lcdfVal_AR2 <- lcdf_AR_LowGrades[indicesValidation2, ]
lcdfTst_AR2 <- lcdf_AR_LowGrades[indicesTest2, ]
```

# 4 XGBOOST Builing the model for grades C and lower

```{r, output.lines=70,, output.lenght=32}

#Needs all data to be numeric -- so we convert categorical 
#(i.e. factor) variables using one-hot encoding 
# we use the dummyVars function in the 'caret' package 
#to convert factor variables to # dummy-variables
fdum4<-dummyVars(~.,data=lcdf_AR_LowGrades %>% select(-loan_status)) #do not include loan_status for this
dxlcdf4 <- predict(fdum4, lcdf_AR_LowGrades)

# for loan_status, check levels and convert to dummy vars and keep the class label of interest
levels(lcdf_AR_LowGrades$loan_status)
dylcdf4 <- class2ind(lcdf_AR_LowGrades$loan_status, drop2nd = FALSE)
# and then decide which one to keep
#fplcdf <- dycldf [ , 2] # or, 
colcdf4 <- dylcdf4 [ , 1]

#Training, test subsets
dxlcdfTrn4 <- dxlcdf4[indicesTraining2,]
colcdfTrn4 <- colcdf4[indicesTraining2]
dxlcdfTst4 <- dxlcdf4[indicesTest2,]
colcdfTst4 <- colcdf4[indicesTest2]

dxTrn4 <- xgb.DMatrix(subset(dxlcdfTrn4, select=-c(annRet, actualTerm, actualReturn)), label=colcdfTrn4) 
dxTst4 <- xgb.DMatrix(subset(dxlcdfTst4,select=-c(annRet, actualTerm, actualReturn)), label=colcdfTst4) #colcdf is the same 
#er picked in loan status to dummy variable step
# (annRet, actualTerm, actualReturn, total_pymnt) 
#These variables are useful for performance assessment, 
#but should not be used in the model

xgbWatchlist4 <- list(train = dxTrn4, eval = dxTst4)
#we can watch the progress of learning thru performance on these datasets
# Include a gbWatchlist so the eearly_stopping_rounds = 10 
#that you are goint to use in the model can use 
#it as a base to know when to stop

#Calculating weights
sqrt(sum(dxlcdfTrn4==0) / sum(dxlcdfTrn4==1))  #8.50

#use cross-validation on training dataset to determine best model
xgbParamGrid4 <- expand.grid( max_depth = c(2, 5), eta = c(0.001, 0.01, 0.1))
xgbParam4 <- list (booster = "gbtree", objective = "binary:logistic", min_child_weight=1, colsample_bytree=0.6,eval_metric="error", eval_metric = "auc",scale_pos_weight = 8.50)

for(i in 1:nrow(xgbParamGrid4)) {
xgb_tune4<- xgb.train(data=dxTrn4,xgbParam4,
nrounds=1000, early_stopping_rounds = 10, xgbWatchlist4,
eta=xgbParamGrid4$eta[i], max_depth=xgbParamGrid4$max_depth[i] )
xgbParamGrid4$bestTree[i] <- xgb_tune4$evaluation_log[xgb_tune4$best_iteration]$iter
xgbParamGrid4$bestPerf[i] <- xgb_tune4$evaluation_log[xgb_tune4$best_iteration]$eval_auc
}

```

```{r, output.lenght=32}
xgbParamGrid4

# max_depth eta bestTree bestPerf
# 2	0.001	9	0.572419	 <--
# 5	0.001	73	0.589245	
# 2	0.010	19	0.579483	
# 5	0.010	48	0.593521	
# 2	0.100	93	0.607490	
# 5	0.100	40	0.600758

xgbParam_Best4 <- list (booster = "gbtree", objective = "binary:logistic", min_child_weight=1, colsample_bytree=0.6, max_depth = 2, eta = 0.001,scale_pos_weight = 8.50)

# XGBOOST running the model with the best parameters found with the for loop 
xgb_lsM4 <- xgb.train(xgbParam_Best4, dxTrn4, nrounds = xgb_tune4$best_iteration)

#XGBOOST evaluation of the model
#Using the predicting function to get the scores in the training data  set
xpredTrn4<-predict(xgb_lsM4, dxTrn4)
head(xpredTrn4)

#Using the predicting function to get the scores in the test data set
xpredTst4<-predict(xgb_lsM4, dxTst4)

#confusion matrix 
table(pred=as.numeric(xpredTst4>0.5), act=colcdfTst4)

#ROC, AUC performance
pred_xgb_lsM4<-prediction(xpredTst4, lcdfTst_AR2$loan_status,
label.ordering = c("Fully Paid", ("Charged Off")))

aucPerf_xgb_lsM4<-performance(pred_xgb_lsM4, "tpr", "fpr")
plot(aucPerf_xgb_lsM4)
abline(a=0, b= 1)

```

# 4 XGBOOST Deciles for grades C and lower M1

```{r, output.lenght=32}

xpredTstM4<-predict(xgb_lsM4, dxTst4)

scoreTst_xgb_ls4 <- lcdfTst_AR2 %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score4=xpredTstM4)

scoreTst_xgb_ls4 <- scoreTst_xgb_ls4 %>% mutate(tile=ntile(-score4, 10))
scoreTst_xgb_ls4 %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score4), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm),totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totE=sum(grade=="G"), )

```

\#XGBOOST Model 2 Actual returns for lower grades \#Finding which hyper-parameters work best -- experiment with a grid of parameter values

```{r, output.lenght=32}
# we are predicting actualReturn a numeric variable

#converting factor variables to dummy-variables
fdum5<-dummyVars(~.,lcdf_AR_LowGrades %>% select(-actualReturn))

dxlcdf5 <- predict(fdum5, lcdf_AR_LowGrades)

#Training, test subsets
dxlcdfTrn5 <- dxlcdf5[indicesTraining2,] 
colcdfTrn5 <- lcdf_AR_LowGrades$actualReturn[indicesTraining2]
dxlcdfTst5 <- dxlcdf5[-indicesTraining2,]
colcdfTst5 <- lcdf_AR_LowGrades$actualReturn[indicesTest2]

#Creating Training and Test xgb matrices need it to run the model
dxTrn5 <- xgb.DMatrix(subset(dxlcdfTrn5, select=-c(annRet, actualTerm)), label=colcdfTrn5)
dxTst5 <- xgb.DMatrix(subset(dxlcdfTst5,select=-c(annRet, actualTerm)), label=colcdfTst5)
# (annRet, actualTerm) These variables are useful 
#for performance assessment, but should not be used in the model

xgbWatchlist5 <- list(train = dxTrn5, eval = dxTst5)
#we can watch the progress of learning thru performance on these datasets
# Including a xgbWatchlist so the early_stopping_rounds = 10 
#that we are going to use in the model can use it as a base to know when to stop
```

```{r, output.lines=30, output.lenght=32}
#Parameter with the grid of options we want 
#to test to find the best for the model
xgbParamGrid5 <- expand.grid(
max_depth = c(2, 5),
eta = c(0.001, 0.01, 0.1) )

#Parameter list
xgbParam5 <- list (
booster = "gbtree",
objective = "reg:squarederror",
#scale_pos_weight = 7.950299,
min_child_weight=1,
colsample_bytree=0.6
)

for(i in 1:nrow(xgbParamGrid5)) {
xgb_tune5<- xgb.train(data=dxTrn5,xgbParam5,
nrounds=1000, early_stopping_rounds = 10, xgbWatchlist5,
eta=xgbParamGrid5$eta[i], max_depth=xgbParamGrid5$max_depth[i] )
xgbParamGrid5$bestTree[i] <- xgb_tune5$evaluation_log[xgb_tune5$best_iteration]$iter
xgbParamGrid5$bestPerf[i] <- xgb_tune5$evaluation_log[xgb_tune5$best_iteration]$eval_rmse
}

```

\#Plugin the tune parameters

```{r, output.lenght=32}
xgbParamGrid5 

# max_depth eta bestTree bestPerf
# 2	0.001	1000	6.764726	
# 5	0.001	1000	6.805881	
# 2	0.010	824	5.004813	
# 5	0.010	640	4.988406	
# 2	0.100	132	5.001203	<.
# 5	0.100	60	4.999652		

xgbParam6 <- list(
max_depth = 2,
eta = 0.100,
booster = "gbtree",
objective = "reg:squarederror",
#scale_pos_weight = 7.950299,
min_child_weight=1,
colsample_bytree=0.6
)

# XGBOOST running the model with the best parameters found with the for loop 
xgb_lsM5 <- xgb.train(xgbParam6, dxTrn5, nrounds = xgb_tune5$best_iteration)
```

\#XGBOOST evaluation of the model

```{r, output.lenght=32}
#Using the predicting function to get the scores in the training data  set
xpredTrn5<-predict(xgb_lsM5, dxTrn5)
head(xpredTrn5)

#Using the predicting function to get the scores in the test data set
xpredTst5<-predict(xgb_lsM5, dxTst5)

#Error
sqrt(mean((xpredTst5- colcdfTst5)^2)) #5.00

```

\#XGBOOST M2 Actual Returns Performance of Boosting grades C and lower

```{r, output.lenght=32}
xpredTstM5<-predict(xgb_lsM5, dxTst5)

scoreTst_xgb_ls5 <- lcdfTst_AR2 %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score5=xpredTstM5)

scoreTst_xgb_ls5 <- scoreTst_xgb_ls5 %>% mutate(tile=ntile(-score5, 10))
scoreTst_xgb_ls5 %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score5), numDefaults=sum(loan_status=="Charged Off"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm),totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totE=sum(grade=="G"))

```

\#XGBOOST -Consider Top d deciles from Model 2(actualReturn), ranked by M1 scores(loan_Status) all grades

```{r, output.lenght=32}
d=1

pRetSc6 <- scoreTst_xgb_ls5 %>% mutate(poScore=scoreTst_xgb_ls4$score4)
pRet_d6 <- pRetSc6 %>% filter(tile<=d)
pRet_d6<- pRet_d6 %>% mutate(tile2=ntile(-poScore, 10))

pRet_d6 %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(score5),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totE=sum(grade=="G"))


```

\#performance of glm model for low grade loans in deciles for M1

```{r, output.lenght=32}

lg_xDTrn<-lg_lcdfTrn %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)

lg_predLS_glm <- lg_lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(lg_score=predict(glmls_cv,data.matrix(lg_xDTrn), s="lambda.min", type="response" ))


lg_predLS_glm<- lg_predLS_glm%>% mutate(tile=ntile(-lg_score, 10))

lg_predLS_glm %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(lg_score),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

\#Actual Retruns selected by grade M2 low grades

```{r, output.lenght=32}
#Performance of glm model for lambda min
lg_predRet_Trn_glm <- lg_lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(lg_predRet_glm=  predict(glmRet_cv, data.matrix(lg_lcdfTrn %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" ))

lg_predRet_Trn_glm<- lg_predRet_Trn_glm%>% mutate(tile=ntile(-lg_predRet_glm, 10))

lg_predRet_Trn_glm %>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(lg_predRet_glm),    numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),    maxRet=max(actualReturn), avgTerm=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

\#glm - Consider Top d deciles from Model 2(actualReturn), ranked by M1 scores(loan_Status) low grades

```{r, output.lenght=32}
d=1
lg_pRetSc_glm <- lg_predRet_Trn_glm %>% mutate(poScore=lg_predLS_glm$lg_score)
lg_pRet_d_glm <- lg_pRetSc_glm %>% filter(tile<=d)
lg_pRet_d_glm<- lg_pRet_d_glm %>% mutate(tile2=ntile(-poScore, 20))


lg_pRet_d_glm %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(lg_predRet_glm),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

## Bonus points

Correlations

```{r warning=FALSE}
library(corrplot)

xCorr <- lcdfTrn_AR %>% select_if(is.numeric) %>%cor()

corrplot(xCorr, method="circle")

#Setting threshold to 0.6
corrTH = 0.6
xCorr[upper.tri(xCorr, diag=TRUE)] <- NA 

#Creating data fame
xCorr <- as.data.frame(as.table(xCorr))
#Remove rows corresponding to NA values
xCorr <- na.omit(xCorr)
#remove the rows with abs(values) < corrTH
xCorr_th <- xCorr %>% filter(abs(Freq) > corrTH) 
#order by the corr values
xCorr_th <- xCorr_th[order(-abs(xCorr_th$Freq)),] 
#Convert back to matrix form to use with corrPlot
xCorrMat <- xCorr_th %>% pivot_wider(names_from = Var2, values_from = Freq)
#convert first column to rownames
xCorrMat<-column_to_rownames(xCorrMat, var="Var1")

corrplot(as.matrix(xCorrMat), is.corr=FALSE, na.label=" ", method="circle")

```

\#AUC

```{r message=FALSE, warning=FALSE}
library(pROC) 

#Or considering both numeric and factor variables:
aucAR<- sapply(lcdfTrn_AR %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), auc, response=lcdfTrn_AR$actualReturn) 

#TO determine which variables have auc > 0.5
aucAR[aucAR>0.5]

#Or, we can use the tidy(..) function from the broom package - which converts the 'messy' output into a tidy form as a tibble
library(broom)

tidy(aucAR[aucAR > 0.5]) %>% view()

# or  in any range of values like, tidy(aucAll[aucAll >=0.5 & aucAll < 0.6])
# or in sorted order
tidy(aucAR) %>% arrange(desc(aucAR))

```

\#Removing variables based on auc score

```{r}
lcdf_AR_auc <- lcdfTrn_AR %>% select(-c(int_rate, grade, sub_grade, purpose, acc_open_past_24mths, bc_open_to_buy, bc_util, mo_sin_rcnt_tl, num_tl_op_past_12m, percent_bc_gt_75, annRet))
```

\#Building A Random Forest with removed auc

```{r}
rf_auc <- ranger(actualReturn ~., data=subset(lcdf_AR_auc, select=-c(actualTerm, loan_status)), num.trees = 200, importance='permutation')
```

\#Rf AUC -- Training data

```{r}
rfPredRet_trn_auc<- predict(rf_auc,  lcdf_AR_auc)
sqrt(mean((rfPredRet_trn_auc$predictions- lcdf_AR_auc$actualReturn)^2))

plot ((predict(rf_auc,  lcdf_AR_auc))$predictions, lcdf_AR_auc$actualReturn)
```
